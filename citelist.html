<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Bibliography | OpenVINS</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,600i%7CSource+Code+Pro:400,400i,600&amp;subset=latin-ext" />
  <link rel="stylesheet" href="m-udel+documentation.compiled.css" />
  <link rel="stylesheet" href="custom.css" />
  <link rel="icon" href="favicon-light.png" type="image/png" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#2f73a3" />
</head>
<body>
<header><nav id="navigation">
  <div class="m-container">
    <div class="m-row">
      <a href="index.html" id="m-navbar-brand" class="m-col-t-8 m-col-m-none m-left-m">OpenVINS</a>
      <div class="m-col-t-4 m-hide-m m-text-right m-nopadr">
        <a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
          <path id="m-doc-search-icon-path" d="m6 0c-3.31 0-6 2.69-6 6 0 3.31 2.69 6 6 6 1.49 0 2.85-0.541 3.89-1.44-0.0164 0.338 0.147 0.759 0.5 1.15l3.22 3.79c0.552 0.614 1.45 0.665 2 0.115 0.55-0.55 0.499-1.45-0.115-2l-3.79-3.22c-0.392-0.353-0.812-0.515-1.15-0.5 0.895-1.05 1.44-2.41 1.44-3.89 0-3.31-2.69-6-6-6zm0 1.56a4.44 4.44 0 0 1 4.44 4.44 4.44 4.44 0 0 1-4.44 4.44 4.44 4.44 0 0 1-4.44-4.44 4.44 4.44 0 0 1 4.44-4.44z"/>
        </svg></a>
        <a id="m-navbar-show" href="#navigation" title="Show navigation"></a>
        <a id="m-navbar-hide" href="#" title="Hide navigation"></a>
      </div>
      <div id="m-navbar-collapse" class="m-col-t-12 m-show-m m-col-m-none m-right-m">
        <div class="m-row">
          <ol class="m-col-t-6 m-col-m-none">
            <li><a href="pages.html">Pages</a></li>
            <li><a href="annotated.html">Classes</a></li>
            <li><a href="namespaceov__core.html">ov_core</a></li>
            <li><a href="namespaceov__type.html">ov_type</a></li>
            <li><a href="namespaceov__msckf.html">ov_msckf</a></li>
            <li><a href="namespaceov__init.html">ov_init</a></li>
            <li><a href="namespaceov__eval.html">ov_eval</a></li>
          </ol>
          <ol class="m-col-t-6 m-col-m-none" start="8">
            <li><a href="https://github.com/rpng/open_vins/">GitHub</a></li>
            <li class="m-show-m"><a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
              <use href="#m-doc-search-icon-path" />
            </svg></a></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</nav></header>
<main><article>
  <div class="m-container m-container-inflatable">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <h1>
          Bibliography
        </h1>
<dl class="m-doc"><dt><a name="CITEREF_ceres-solver"></a>[1]</dt><dd><p>Sameer Agarwal, Keir Mierle, and Others. <a href="http://ceres-solver.org">Ceres solver</a>. <a href="http://ceres-solver.org">http:/<wbr />/<wbr />ceres-solver.org</a>.</p></dd><dt><a name="CITEREF_Bar2001"></a>[2]</dt><dd><p>Yaakov Bar-Shalom, X&nbsp;Rong Li, and Thiagalingam Kirubarajan. <em>Estimation with applications to tracking and navigation: theory algorithms and software</em>. John Wiley &amp; Sons, 2001.</p></dd><dt><a name="CITEREF_Barfoot2017"></a>[3]</dt><dd><p>Timothy&nbsp;D Barfoot. <a href="http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf"><em>State estimation for robotics</em></a>. Cambridge University Press, 2017.</p></dd><dt><a name="CITEREF_Burri2016IJRR"></a>[4]</dt><dd><p>Michael Burri, Janosch Nikolic, Pascal Gohl, Thomas Schneider, Joern Rehder, Sammy Omari, Markus&nbsp;W Achtelik, and Roland Siegwart. The euroc micro aerial vehicle datasets. <em>The International Journal of Robotics Research</em>, 35(10):1157&ndash;1163, 2016.</p></dd><dt><a name="CITEREF_Chatfield1997"></a>[5]</dt><dd><p>Averil&nbsp;Burton Chatfield. <em>Fundamentals of high accuracy inertial navigation</em>, volume 174. Aiaa, 1997.</p></dd><dt><a name="CITEREF_Chen2022ICRA"></a>[6]</dt><dd><p>Chuchu Chen, Yulin Yang, Patrick Geneva, and Guoquan Huang. <a href="https://chuchuchen.net/downloads/papers/Chen2022ICRA.pdf">Fej2: A consistent visual-inertial state estimator design</a>. In <em>2022 International Conference on Robotics and Automation (ICRA)</em>, 2022.</p></dd><dt><a name="CITEREF_Chen2023ICRA"></a>[7]</dt><dd><p>Chuchu Chen, Patrick Geneva, Yuxiang Peng, Woosik Lee, and Guoquan Huang. <a href="https://pgeneva.com/downloads/papers/Chen2023ICRA.pdf">Monocular visual-inertial odometry with planar regularities</a>. In <em>2023 International Conference on Robotics and Automation (ICRA)</em>, 2023.</p></dd><dt><a name="CITEREF_Chirikjian2011"></a>[8]</dt><dd><p>Gregory Chirikjian. <em>Stochastic Models, Information Theory, and Lie Groups, Volume 2: Analytic Methods and Modern Applications</em>, volume&nbsp;2. Springer Science &amp; Business Media, 2011.</p></dd><dt><a name="CITEREF_Davidson2009ENC"></a>[9]</dt><dd><p>Pavel Davidson, Jani Hautam&auml;ki, Jussi Collin, and Jarmo Takala. <a href="http://www.tkt.cs.tut.fi/research/nappo_files/1_C2.pdf">Improved vehicle positioning in urban environment through integration of gps and low-cost inertial sensors</a>. In <em>Proceedings of the European Navigation Conference (ENC), Naples, Italy</em>, pages 3&ndash;6, 2009.</p></dd><dt><a name="CITEREF_Delmerico2018ICRA"></a>[10]</dt><dd><p>Jeffrey Delmerico and Davide Scaramuzza. <a href="http://rpg.ifi.uzh.ch/docs/ICRA18_Delmerico.pdf">A benchmark comparison of monocular visual-inertial odometry algorithms for flying robots</a>. In <em>2018 IEEE International Conference on Robotics and Automation (ICRA)</em>, pages 2502&ndash;2509. IEEE, 2018.</p></dd><dt><a name="CITEREF_Dong2012IROS"></a>[11]</dt><dd><p>Tue-Cuong Dong-Si and Anastasios&nbsp;I Mourikis. <a href="http://tdongsi.github.io/download/pubs/DongSi2012IROS.pdf">Estimator initialization in vision-aided inertial navigation with unknown camera-imu calibration</a>. In <em>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, pages 1064&ndash;1071. IEEE, 2012.</p></dd><dt><a name="CITEREF_Eckenhoff2018TR"></a>[12]</dt><dd><p>Kevin Eckenhoff, Patrick Geneva, and Guoquan Huang. Continuous preintegration theory for visual-inertial navigation. Technical Report RPNG-2018-CPI, University of Delaware, 2018. Available: <a href="http://udel.edu/~ghuang/papers/tr_cpi.pdf">http://udel.edu/&amp;nbsp;ghuang/papers/tr_<wbr />cpi.pdf</a>.</p></dd><dt><a name="CITEREF_Eckenhoff2019IJRR"></a>[13]</dt><dd><p>Kevin Eckenhoff, Patrick Geneva, and Guoquan Huang. <a href="https://pgeneva.com/downloads/preprints/Eckenhoff2019IJRR.pdf">Closed-form preintegration methods for graph-based visual-inertial navigation</a>. <em>International Journal of Robotics Research</em>, 38(5), 2019.</p></dd><dt><a name="CITEREF_Farrell2008"></a>[14]</dt><dd><p>Jay Farrell. <em>Aided navigation: GPS with high rate sensors</em>. McGraw-Hill, Inc., 2008.</p></dd><dt><a name="CITEREF_Furgale2013IROS"></a>[15]</dt><dd><p>Paul Furgale, Joern Rehder, and Roland Siegwart. <a href="https://furgalep.github.io/bib/furgale_iros13.pdf">Unified temporal and spatial calibration for multi-sensor systems</a>. In <em>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, pages 1280&ndash;1286. IEEE, 2013.</p></dd><dt><a name="CITEREF_Geneva2020TRVICON2GT"></a>[16]</dt><dd><p>Patrick Geneva and Guoquan Huang. <a href="http://udel.edu/~ghuang/papers/tr_vicon2gt.pdf">vicon2gt: Derivations and analysis</a>. Technical Report RPNG-2020-VICON2GT, University of Delaware, 2020.</p></dd><dt><a name="CITEREF_Hesch2012TR"></a>[17]</dt><dd><p>Joel&nbsp;A. Hesch, Dimitrios&nbsp;G. Kottas, Sean&nbsp;L. Bowman, and Stergios&nbsp;I. Roumeliotis. Observability-constrained vision-aided inertial navigation. Technical report, Dept. of Computer Science &amp; Engineering, University of Minnesota, 2012. Available: <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.721.6118&amp;rep=rep1&amp;type=pdf">https:/<wbr />/<wbr />citeseerx.ist.psu.edu/<wbr />viewdoc/<wbr />download?doi=10.1.1.721.6118&amp;amp;rep=rep1&amp;amp;type=pdf</a>.</p></dd><dt><a name="CITEREF_Hesch2013TRO"></a>[18]</dt><dd><p>Joel&nbsp;A Hesch, Dimitrios&nbsp;G Kottas, Sean&nbsp;L Bowman, and Stergios&nbsp;I Roumeliotis. Consistency analysis and improvement of vision-aided inertial navigation. <em>IEEE Transactions on Robotics</em>, 30(1):158&ndash;176, 2013.</p></dd><dt><a name="CITEREF_Hesch2014IJRR"></a>[19]</dt><dd><p>Joel&nbsp;A Hesch, Dimitrios&nbsp;G Kottas, Sean&nbsp;L Bowman, and Stergios&nbsp;I Roumeliotis. Camera-imu-based localization: Observability analysis and consistency improvement. <em>The International Journal of Robotics Research</em>, 33(1):182&ndash;201, 2014.</p></dd><dt><a name="CITEREF_Huang2009ISER"></a>[20]</dt><dd><p>Guoquan&nbsp;P Huang, Anastasios&nbsp;I Mourikis, and Stergios&nbsp;I Roumeliotis. <a href="https://intra.ece.ucr.edu/~mourikis/papers/Huang08-ISER.pdf">A first-estimates jacobian ekf for improving slam consistency</a>. In <em>Experimental Robotics: The Eleventh International Symposium</em>, pages 373&ndash;382. Springer, 2009.</p></dd><dt><a name="CITEREF_Huang2010IJRR"></a>[21]</dt><dd><p>Guoquan&nbsp;P Huang, Anastasios&nbsp;I Mourikis, and Stergios&nbsp;I Roumeliotis. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.228.5851&amp;rep=rep1&amp;type=pdf">Observability-based rules for designing consistent ekf slam estimators</a>. <em>The International Journal of Robotics Research</em>, 29(5):502&ndash;528, 2010.</p></dd><dt><a name="CITEREF_Jeon2021RAL"></a>[22]</dt><dd><p>Jinwoo Jeon, Sungwook Jung, Eungchang Lee, Duckyu Choi, and Hyun Myung. Run your visual-inertial odometry on nvidia jetson: Benchmark tests on a micro aerial vehicle. <em>IEEE Robotics and Automation Letters</em>, 6(3):5332&ndash;5339, 2021.</p></dd><dt><a name="CITEREF_Jeong2019IJRR"></a>[23]</dt><dd><p>Jinyong Jeong, Younggun Cho, Young-Sik Shin, Hyunchul Roh, and Ayoung Kim. Complex urban dataset with multi-level sensors from highly diverse urban environments. <em>The International Journal of Robotics Research</em>, 38(6):642&ndash;657, 2019.</p></dd><dt><a name="CITEREF_Kay1993"></a>[24]</dt><dd><p>Steven&nbsp;M Kay. <a href="http://users.isr.ist.utl.pt/~pjcro/temp/Fundamentals%20Of%20Statistical%20Signal%20Processing%2D%2DEstimation%20Theory-Kay.pdf"><em>Fundamentals of statistical signal processing</em></a>. Prentice Hall PTR, 1993.</p></dd><dt><a name="CITEREF_Lee2020IROS"></a>[25]</dt><dd><p>Woosik Lee, Kevin Eckenhoff, Yulin Yang, Patrick Geneva, and Guoquan Huang. <a href="http://udel.edu/~ghuang/papers/tr_wheel-vio.pdf">Visual-inertial-wheel odometry with online calibration</a>. In <em>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, pages 4559&ndash;4566. IEEE, 2020.</p></dd><dt><a name="CITEREF_Li2012TR"></a>[26]</dt><dd><p>Mingyang Li and Anastasios&nbsp;I. Mourikis. Consistency of ekf-based visual-inertial odometry. Technical report, Dept. of Electrical Engineering, University of California, Riverside, 2012. Available: <a href="https://intra.ece.ucr.edu/~mourikis/tech_reports/VIO.pdf">https://intra.ece.ucr.edu/&amp;nbsp;mourikis/tech_<wbr />reports/VIO.pdf</a>.</p></dd><dt><a name="CITEREF_Li2013IJRR"></a>[27]</dt><dd><p>Mingyang Li and Anastasios&nbsp;I Mourikis. <a href="https://intra.ece.ucr.edu/~mourikis/papers/Li2013IJRR.pdf">High-precision, consistent ekf-based visual-inertial odometry</a>. <em>The International Journal of Robotics Research</em>, 32(6):690&ndash;711, 2013.</p></dd><dt><a name="CITEREF_Li2014IJRR"></a>[28]</dt><dd><p>Mingyang Li and Anastasios&nbsp;I Mourikis. Online temporal calibration for camera&ndash;imu systems: Theory and algorithms. <em>The International Journal of Robotics Research</em>, 33(7):947&ndash;964, 2014.</p></dd><dt><a name="CITEREF_Li2014ICRA"></a>[29]</dt><dd><p>Mingyang Li, Hongsheng Yu, Xing Zheng, , and Anastasios&nbsp;I. Mourikis. High-fidelity sensor modeling and self-calibration in vision-aided inertial navigation. In <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, pages 409&ndash;416, May 2014.</p></dd><dt><a name="CITEREF_Li2014THESIS"></a>[30]</dt><dd><p>Mingyang Li. <a href="https://escholarship.org/uc/item/4nn0j264"><em>Visual-inertial odometry on resource-constrained systems</em></a>. PhD thesis, UC Riverside, 2014.</p></dd><dt><a name="CITEREF_Maybeck1982STOC"></a>[31]</dt><dd><p>Peter&nbsp;S Maybeck. <a href="https://books.google.com/books?id=L_YVMUJKNQUC"><em>Stochastic models, estimation, and control</em></a>, volume&nbsp;3. Academic press, 1982.</p></dd><dt><a name="CITEREF_Mourikis2007ICRA"></a>[32]</dt><dd><p>Anastasios&nbsp;I Mourikis and Stergios&nbsp;I Roumeliotis. <a href="https://www-users.cse.umn.edu/~stergios/papers/ICRA07-MSCKF.pdf">A multi-state constraint kalman filter for vision-aided inertial navigation</a>. In <em>Proceedings 2007 IEEE International Conference on Robotics and Automation</em>, pages 3565&ndash;3572. IEEE, 2007.</p></dd><dt><a name="CITEREF_Mueggler2018TRO"></a>[33]</dt><dd><p>E.&nbsp;Mueggler, G.&nbsp;Gallego, H.&nbsp;Rebecq, and D.&nbsp;Scaramuzza. <a href="http://rpg.ifi.uzh.ch/docs/TRO18_Mueggler.pdf">Continuous-time visual-inertial odometry for event cameras</a>. <em>IEEE Transactions on Robotics</em>, pages 1&ndash;16, 2018.</p></dd><dt><a name="CITEREF_Patron2015IJCV"></a>[34]</dt><dd><p>Alonso Patron-Perez, Steven Lovegrove, and Gabe Sibley. A spline-based trajectory representation for sensor fusion and rolling shutter cameras. <em>International Journal of Computer Vision</em>, 113(3):208&ndash;219, 2015.</p></dd><dt><a name="CITEREF_Qin2018TRO"></a>[35]</dt><dd><p>Tong Qin, Peiliang Li, and Shaojie Shen. <a href="https://arxiv.org/pdf/1708.03852.pdf">VINS-Mono: A robust and versatile monocular visual-inertial state estimator</a>. <em>IEEE Transactions on Robotics</em>, 34(4):1004&ndash;1020, 2018.</p></dd><dt><a name="CITEREF_Ramanandan2011TITS"></a>[36]</dt><dd><p>Arvind Ramanandan, Anning Chen, and Jay&nbsp;A Farrell. Inertial navigation aiding by stationary updates. <em>IEEE Transactions on Intelligent Transportation Systems</em>, 13(1):235&ndash;248, 2011.</p></dd><dt><a name="CITEREF_Rehder2017Sensors"></a>[37]</dt><dd><p>Joern Rehder and Roland Siegwart. Camera/imu calibration revisited. <em>IEEE Sensors Journal</em>, 17(11):3257&ndash;3268, 2017.</p></dd><dt><a name="CITEREF_Schneider2019Sensor"></a>[38]</dt><dd><p>Thomas Schneider, Mingyang Li, Cesar Cadena, Juan Nieto, and Roland Siegwart. <a href="https://arxiv.org/pdf/1901.07242.pdf">Observability-aware self-calibration of visual and inertial sensors for ego-motion estimation</a>. <em>IEEE Sensors Journal</em>, 19(10):3846&ndash;3860, 2019.</p></dd><dt><a name="CITEREF_Schubert2018IROS"></a>[39]</dt><dd><p>David Schubert, Thore Goll, Nikolaus Demmel, Vladyslav Usenko, J&nbsp; &ouml; &nbsp;rg St&nbsp; &uuml; &nbsp;ckler, and Daniel Cremers. <a href="https://arxiv.org/pdf/1804.06120.pdf">The tum vi benchmark for evaluating visual-inertial odometry</a>. In <em>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, pages 1680&ndash;1687. IEEE, 2018.</p></dd><dt><a name="CITEREF_Trawny2005TR"></a>[40]</dt><dd><p>Nikolas Trawny and Stergios&nbsp;I Roumeliotis. <a href="http://mars.cs.umn.edu/tr/reports/Trawny05b.pdf">Indirect kalman filter for 3d attitude estimation</a>. <em>University of Minnesota, Dept. of Comp. Sci. &amp; Eng., Tech. Rep</em>, 2:2005, 2005.</p></dd><dt><a name="CITEREF_Wagstaff2017IPIN"></a>[41]</dt><dd><p>Brandon Wagstaff, Valentin Peretroukhin, and Jonathan Kelly. <a href="https://arxiv.org/pdf/1707.01152.pdf">Improving foot-mounted inertial navigation through real-time motion classification</a>. In <em>2017 International Conference on Indoor Positioning and Indoor Navigation (IPIN)</em>, pages 1&ndash;8. IEEE, 2017.</p></dd><dt><a name="CITEREF_Wu2017ICRA"></a>[42]</dt><dd><p>Kejian&nbsp;J Wu, Chao&nbsp;X Guo, Georgios Georgiou, and Stergios&nbsp;I Roumeliotis. <a href="http://mars.cs.umn.edu/papers/KejianWu_VINSonWheels.pdf">VINS on wheels</a>. In <em>2017 IEEE International Conference on Robotics and Automation (ICRA)</em>, pages 5155&ndash;5162. IEEE, 2017.</p></dd><dt><a name="CITEREF_Yang2019TR_ACI"></a>[43]</dt><dd><p>Yulin Yang, Chuchu Chen, and Guoquan Huang. Supplementary material: Analytic combined imu integrator (aci<sup>2</sup>) for visual inertial navigation. Technical report, RPNG, University of Delaware, 2019. Available: <a href="http://udel.edu/~yuyang/downloads/suplementary_2020ICRA.pdf">http://udel.edu/&amp;nbsp;yuyang/downloads/suplementary_<wbr />2020ICRA.pdf</a>.</p></dd><dt><a name="CITEREF_Yang2020ICRA"></a>[44]</dt><dd><p>Yulin Yang, B.&nbsp;P.&nbsp;W. Babu, Chuchu Chen, Guoquan Huang, and Liu Ren. <a href="https://yangyulin.net/papers/2020_icra_aci.pdf">Analytic combined imu integration (aci<sup>2</sup>) for visual-inertial navigation</a>. In <em>Proc. of the IEEE International Conference on Robotics and Automation</em>, Paris, France, 2020.</p></dd><dt><a name="CITEREF_Yang2020RSS"></a>[45]</dt><dd><p>Yulin Yang, Patrick Geneva, Xingxing Zuo, and Guoquan Huang. <a href="http://www.roboticsproceedings.org/rss16/p026.pdf">Online imu intrinsic calibration: Is it necessary?</a>. <em>Proc. of Robotics: Science and Systems (RSS), Corvallis, Or</em>, 2020.</p></dd><dt><a name="CITEREF_Yang2023TRO"></a>[46]</dt><dd><p>Xingxing Zuo Guoquan&nbsp;Huang Yulin&nbsp;Yang, Patrick&nbsp;Geneva. <a href="https://pgeneva.com/downloads/preprints/Yang2023TRO.pdf">Online self-calibration for visual-inertial navigation: Models, analysis and degeneracy</a>. <em>IEEE Transactions on Robotics</em>, 2023.</p></dd><dt><a name="CITEREF_Zhang2018IROS"></a>[47]</dt><dd><p>Zichao Zhang and Davide Scaramuzza. <a href="http://rpg.ifi.uzh.ch/docs/IROS18_Zhang.pdf">A tutorial on quantitative trajectory evaluation for visual(-inertial) odometry</a>. In <em>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, pages 7244&ndash;7251. IEEE, 2018.</p></dd></dl>
      </div>
    </div>
  </div>
</article></main>
<div class="m-doc-search" id="search">
  <a href="#!" onclick="return hideSearch()"></a>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-m-8 m-push-m-2">
        <div class="m-doc-search-header m-text m-small">
          <div><span class="m-label m-default">Tab</span> / <span class="m-label m-default">T</span> to search, <span class="m-label m-default">Esc</span> to close</div>
          <div id="search-symbolcount">&hellip;</div>
        </div>
        <div class="m-doc-search-content">
          <form>
            <input type="search" name="q" id="search-input" placeholder="Loading &hellip;" disabled="disabled" autofocus="autofocus" autocomplete="off" spellcheck="false" />
          </form>
          <noscript class="m-text m-danger m-text-center">Unlike everything else in the docs, the search functionality <em>requires</em> JavaScript.</noscript>
          <div id="search-help" class="m-text m-dim m-text-center">
            <p class="m-noindent">Search for symbols, directories, files, pages or
            modules. You can omit any prefix from the symbol or file path; adding a
            <code>:</code> or <code>/</code> suffix lists all members of given symbol or
            directory.</p>
            <p class="m-noindent">Use <span class="m-label m-dim">&darr;</span>
            / <span class="m-label m-dim">&uarr;</span> to navigate through the list,
            <span class="m-label m-dim">Enter</span> to go.
            <span class="m-label m-dim">Tab</span> autocompletes common prefix, you can
            copy a link to the result using <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">L</span> while <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">M</span> produces a Markdown link.</p>
          </div>
          <div id="search-notfound" class="m-text m-warning m-text-center">Sorry, nothing was found.</div>
          <ul id="search-results"></ul>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="search-v1.js"></script>
<script src="searchdata-v1.js" async="async"></script>
<footer><nav>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <p>Generated by <a href="https://doxygen.org/">Doxygen</a> 1.8.20 and <a href="https://mcss.mosra.cz/">m.css</a>.</p>
      </div>
    </div>
  </div>
</nav></footer>
</body>
</html>
